{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1ojcRojUI2u"
   },
   "source": [
    "## Assigment 3: Transformers for translation ðŸ™Š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbsZ8_HXD1bV"
   },
   "source": [
    "Have you ever wondered how applications like Google Translate or language translation features in social media platforms work? Behind these impressive technologies are sophisticated machine learning models that can understand and translate text between different languages. One of the most powerful and groundbreaking models used for this purpose is the Transformer model.\n",
    "\n",
    "In this assignment, you will step into the shoes of an AI researcher and engineer to create your own Transformer model for translating text from English to French. This journey will not only enhance your understanding of machine learning and deep learning but also give you hands-on experience with state-of-the-art techniques in natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkOvjxXZEmRn"
   },
   "source": [
    "Let's start by downloading important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "SWDs3o4jvnzn",
    "outputId": "b26ba8f2-a82e-498b-e1e4-6c7264ec8045"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.0+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.44.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.24.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install transformers\n",
    "!pip install bert_score\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4o0FXVqEsMb"
   },
   "source": [
    "For this assignment we are using the IWSLT2017 dataset (read more about it [here](https://huggingface.co/datasets/IWSLT/iwslt2017) ). This dataset easily found in Huggingface fits perfectly for our machine translation task."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnyUFsrLuKen",
    "outputId": "b22e04d4-9efd-4505-ef2b-4a1916dfabe4",
    "ExecuteTime": {
     "end_time": "2024-12-09T04:16:12.752298Z",
     "start_time": "2024-12-09T04:16:03.454591Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "nltk.download('stopwords')\n",
    "dataset = load_dataset(\"IWSLT/iwslt2017\",'iwslt2017-en-fr')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The repository for IWSLT/iwslt2017 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/IWSLT/iwslt2017.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mamp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradScaler, autocast\n\u001B[1;32m---> 14\u001B[0m dataset \u001B[38;5;241m=\u001B[39m load_dataset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIWSLT/iwslt2017\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124miwslt2017-en-fr\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\datasets\\load.py:2132\u001B[0m, in \u001B[0;36mload_dataset\u001B[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[0;32m   2127\u001B[0m verification_mode \u001B[38;5;241m=\u001B[39m VerificationMode(\n\u001B[0;32m   2128\u001B[0m     (verification_mode \u001B[38;5;129;01mor\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mBASIC_CHECKS) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m save_infos \u001B[38;5;28;01melse\u001B[39;00m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS\n\u001B[0;32m   2129\u001B[0m )\n\u001B[0;32m   2131\u001B[0m \u001B[38;5;66;03m# Create a dataset builder\u001B[39;00m\n\u001B[1;32m-> 2132\u001B[0m builder_instance \u001B[38;5;241m=\u001B[39m load_dataset_builder(\n\u001B[0;32m   2133\u001B[0m     path\u001B[38;5;241m=\u001B[39mpath,\n\u001B[0;32m   2134\u001B[0m     name\u001B[38;5;241m=\u001B[39mname,\n\u001B[0;32m   2135\u001B[0m     data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[0;32m   2136\u001B[0m     data_files\u001B[38;5;241m=\u001B[39mdata_files,\n\u001B[0;32m   2137\u001B[0m     cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   2138\u001B[0m     features\u001B[38;5;241m=\u001B[39mfeatures,\n\u001B[0;32m   2139\u001B[0m     download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m   2140\u001B[0m     download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[0;32m   2141\u001B[0m     revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   2142\u001B[0m     token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m   2143\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m   2144\u001B[0m     trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code,\n\u001B[0;32m   2145\u001B[0m     _require_default_config_name\u001B[38;5;241m=\u001B[39mname \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2146\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig_kwargs,\n\u001B[0;32m   2147\u001B[0m )\n\u001B[0;32m   2149\u001B[0m \u001B[38;5;66;03m# Return iterable dataset in case of streaming\u001B[39;00m\n\u001B[0;32m   2150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m streaming:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\datasets\\load.py:1853\u001B[0m, in \u001B[0;36mload_dataset_builder\u001B[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001B[0m\n\u001B[0;32m   1851\u001B[0m     download_config \u001B[38;5;241m=\u001B[39m download_config\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m download_config \u001B[38;5;28;01melse\u001B[39;00m DownloadConfig()\n\u001B[0;32m   1852\u001B[0m     download_config\u001B[38;5;241m.\u001B[39mstorage_options\u001B[38;5;241m.\u001B[39mupdate(storage_options)\n\u001B[1;32m-> 1853\u001B[0m dataset_module \u001B[38;5;241m=\u001B[39m dataset_module_factory(\n\u001B[0;32m   1854\u001B[0m     path,\n\u001B[0;32m   1855\u001B[0m     revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   1856\u001B[0m     download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m   1857\u001B[0m     download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[0;32m   1858\u001B[0m     data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[0;32m   1859\u001B[0m     data_files\u001B[38;5;241m=\u001B[39mdata_files,\n\u001B[0;32m   1860\u001B[0m     cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   1861\u001B[0m     trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code,\n\u001B[0;32m   1862\u001B[0m     _require_default_config_name\u001B[38;5;241m=\u001B[39m_require_default_config_name,\n\u001B[0;32m   1863\u001B[0m     _require_custom_configs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m(config_kwargs),\n\u001B[0;32m   1864\u001B[0m )\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;66;03m# Get dataset builder class from the processing script\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m builder_kwargs \u001B[38;5;241m=\u001B[39m dataset_module\u001B[38;5;241m.\u001B[39mbuilder_kwargs\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\datasets\\load.py:1729\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[0;32m   1724\u001B[0m                 \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1725\u001B[0m                     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[0;32m   1726\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any data file at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1727\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m on the Hugging Face Hub either: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e1)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me1\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1728\u001B[0m                     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1729\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e1 \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1730\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m trust_remote_code:\n\u001B[0;32m   1731\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[0;32m   1732\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a dataset script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or any data file in the same directory.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1733\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\datasets\\load.py:1679\u001B[0m, in \u001B[0;36mdataset_module_factory\u001B[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001B[0m\n\u001B[0;32m   1670\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1671\u001B[0m     \u001B[38;5;66;03m# Otherwise we must use the dataset script if the user trusts it\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m HubDatasetModuleFactoryWithScript(\n\u001B[0;32m   1673\u001B[0m         path,\n\u001B[0;32m   1674\u001B[0m         commit_hash\u001B[38;5;241m=\u001B[39mcommit_hash,\n\u001B[0;32m   1675\u001B[0m         download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m   1676\u001B[0m         download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[0;32m   1677\u001B[0m         dynamic_modules_path\u001B[38;5;241m=\u001B[39mdynamic_modules_path,\n\u001B[0;32m   1678\u001B[0m         trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code,\n\u001B[1;32m-> 1679\u001B[0m     )\u001B[38;5;241m.\u001B[39mget_module()\n\u001B[0;32m   1680\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError:\n\u001B[0;32m   1681\u001B[0m     \u001B[38;5;66;03m# Use the infos from the parquet export except in some cases:\u001B[39;00m\n\u001B[0;32m   1682\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_dir \u001B[38;5;129;01mor\u001B[39;00m data_files \u001B[38;5;129;01mor\u001B[39;00m (revision \u001B[38;5;129;01mand\u001B[39;00m revision \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\datasets\\load.py:1329\u001B[0m, in \u001B[0;36mHubDatasetModuleFactoryWithScript.get_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1322\u001B[0m importable_file_path \u001B[38;5;241m=\u001B[39m _get_importable_file_path(\n\u001B[0;32m   1323\u001B[0m     dynamic_modules_path\u001B[38;5;241m=\u001B[39mdynamic_modules_path,\n\u001B[0;32m   1324\u001B[0m     module_namespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1325\u001B[0m     subdirectory_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mhash\u001B[39m,\n\u001B[0;32m   1326\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m   1327\u001B[0m )\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(importable_file_path):\n\u001B[1;32m-> 1329\u001B[0m     trust_remote_code \u001B[38;5;241m=\u001B[39m resolve_trust_remote_code(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrust_remote_code, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trust_remote_code:\n\u001B[0;32m   1331\u001B[0m         _create_importable_file(\n\u001B[0;32m   1332\u001B[0m             local_path\u001B[38;5;241m=\u001B[39mlocal_path,\n\u001B[0;32m   1333\u001B[0m             local_imports\u001B[38;5;241m=\u001B[39mlocal_imports,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1339\u001B[0m             download_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownload_mode,\n\u001B[0;32m   1340\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\comp6781\\Lib\\site-packages\\datasets\\load.py:138\u001B[0m, in \u001B[0;36mresolve_trust_remote_code\u001B[1;34m(trust_remote_code, repo_id)\u001B[0m\n\u001B[0;32m    135\u001B[0m         signal\u001B[38;5;241m.\u001B[39malarm(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    137\u001B[0m         \u001B[38;5;66;03m# OS which does not support signal.SIGALRM\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    139\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe repository for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m contains custom code which must be executed to correctly \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    140\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload the dataset. You can inspect the repository content at https://hf.co/datasets/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    141\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease pass the argument `trust_remote_code=True` to allow custom code to be run.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    142\u001B[0m         )\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;66;03m# For the CI which might put the timeout at 0\u001B[39;00m\n\u001B[0;32m    145\u001B[0m     _raise_timeout_error(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mValueError\u001B[0m: The repository for IWSLT/iwslt2017 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/IWSLT/iwslt2017.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e9gOL_wFNUV"
   },
   "source": [
    "Just to have an idea let's have a quick peak at what our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlW6pxwZxSZJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e68a99ce-907c-4a88-bb86-39d144e16683"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'en': \"Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\",\n",
       " 'fr': \"Merci beaucoup, Chris. C'est vraiment un honneur de pouvoir venir sur cette scÃ¨ne une deuxiÃ¨me fois. Je suis trÃ¨s reconnaissant.\"}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset['train']['translation'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oL3XE7WHMWiw"
   },
   "source": [
    "Since we don't want to take 8 hours training, let's trim our dataset a bit (although this might lead to underperformance, feel free to use the complete dataset if you have the computing power)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "SUGESTION: start with a small dataset to debug your code and increase it gradually (the same principle applies for the number of epochs, batch size, test set size...)."
   ],
   "metadata": {
    "id": "dJE2Rf46N9s7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zbZtQGnOS42"
   },
   "outputs": [],
   "source": [
    "trim_dataset= dataset['train']['translation'][:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxGkuEIgsKiU"
   },
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpG6_OkVFW6L"
   },
   "source": [
    "Same as our previous assignments preprocessing is an essential part of any NLP task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-27GvDhsMR6"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def preprocess_data(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = ' '.join([word for word in text.split(\" \") if word.isalpha()])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnLE32PKFoWk"
   },
   "source": [
    "For an easier training structure, it is useful to format our training and validation sets. The following function should help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbUiwe6JvZ_c"
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset,source_lang,target_lang):\n",
    "    new_dataset = []\n",
    "    for example in dataset:\n",
    "        source_text = example.get(source_lang, \"\")\n",
    "        target_text = example.get(target_lang, \"\")\n",
    "        clean_source = preprocess_data(source_text)\n",
    "        clean_target = preprocess_data(target_text)\n",
    "        new_dataset.append((clean_source, clean_target))\n",
    "    return new_dataset\n",
    "\n",
    "training_set=create_dataset(trim_dataset,'en','fr')\n",
    "validation_set=create_dataset(dataset['validation']['translation'],'en','fr')\n",
    "test_set=create_dataset(dataset['test']['translation'],'en','fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AN8JIQ8Y71o"
   },
   "source": [
    "### Model Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-IJWkSbzZeT"
   },
   "source": [
    "Now that our data is ready, we can get started. Let's start by creating our Sequence to Sequence Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpTlmB1t3cii"
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def positional_encoding(self, d_model, maxlen=5000):\n",
    "        pos = torch.arange(0, maxlen).unsqueeze(1)\n",
    "        denominator = 10000 ** (torch.arange(0, d_model, 2) / d_model)\n",
    "\n",
    "        PE = torch.zeros((maxlen, d_model))\n",
    "        PE[:, 0::2] = torch.sin(pos / denominator)\n",
    "        PE[:, 1::2] = torch.cos(pos / denominator)\n",
    "\n",
    "        return PE.unsqueeze(0)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        src = self.src_embedding(src)\n",
    "        tgt = self.tgt_embedding(tgt)\n",
    "        positional_encoding = self.positional_encoding(d_model=src.shape[2]).to(src.device)\n",
    "        src_emb = src + positional_encoding[:, :src.shape[1], :]\n",
    "        tgt_emb = tgt + positional_encoding[:, :tgt.shape[1], :]\n",
    "        output = self.transformer(\n",
    "            src_emb, tgt_emb,\n",
    "            src_mask, tgt_mask,\n",
    "            None,\n",
    "            src_key_padding_mask, tgt_key_padding_mask,\n",
    "            src_key_padding_mask\n",
    "        )\n",
    "        return self.fc(output)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.src_embedding(src)\n",
    "        positional_encoding = self.positional_encoding(d_model=src.shape[2]).to(src.device)\n",
    "        src_emb = src + positional_encoding[:, :src.shape[1], :]\n",
    "        return self.transformer.encoder(src_emb, src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        tgt = self.tgt_embedding(tgt)\n",
    "        positional_encoding = self.positional_encoding(d_model=tgt.shape[2]).to(tgt.device)\n",
    "        tgt_emb = tgt + positional_encoding[:, :tgt.shape[1], :]\n",
    "        return self.transformer.decoder(tgt_emb, memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FodHRx7pRD6"
   },
   "source": [
    "Now that our model is ready, we still need some methods that will come in handy during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4S8Ys4-OJ4Mj"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    return (seq == 0).float()\n",
    "\n",
    "def create_triu_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz), diagonal=1).transpose(0, 1).float()\n",
    "    mask = mask.masked_fill(mask == 1, float('-inf')).masked_fill(mask == 0, float(0.0))\n",
    "    return torch.flip(mask, dims=(0, 1))\n",
    "\n",
    "def tokenize_batch(source, targets, tokenizer):\n",
    "    tokenized_source = tokenizer(source, padding='max_length', max_length=120, truncation=True, return_tensors='pt')\n",
    "    tokenized_targets = tokenizer(targets, padding='max_length', max_length=120, truncation=True, return_tensors='pt')\n",
    "    return tokenized_source['input_ids'], tokenized_targets['input_ids']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7qBZbprY_a0"
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained('FacebookAI/xlm-roberta-base')\n",
    "PAD_IDX = tokenizer.pad_token_id\n",
    "BOS_IDX = tokenizer.bos_token_id\n",
    "EOS_IDX = tokenizer.eos_token_id\n",
    "\n",
    "model = TransformerModel(tokenizer.vocab_size, tokenizer.vocab_size,512, 8, 3, 3, 256,0.1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "id": "2pKk5iK1jJAB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "outputId": "b23d7c23-7f16-4013-e1e7-2528bd380a37"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-2a001dfb52af>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAutoTokenizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mAutoTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'FacebookAI/xlm-roberta-base'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tF7sRoh7_VBe"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast\n",
    "from tqdm import tqdm\n",
    "def train_epoch(model, train_loader, tokenizer, scaler, accumulation_steps=4):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for batch_idx, (src, tgt) in enumerate(tqdm(train_loader)):\n",
    "        src, tgt = tokenize_batch(src, tgt, tokenizer)\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_out = tgt[:, 1:]\n",
    "\n",
    "        src_mask = torch.zeros((src.size(1), src.size(1)), device=device)\n",
    "        tgt_mask = create_triu_mask(tgt_input.size(1)).to(device)\n",
    "        src_padding_mask = create_padding_mask(src).to(device)\n",
    "        tgt_padding_mask = create_padding_mask(tgt_input).to(device)\n",
    "        with autocast(device_type='cuda'):\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_mask=src_mask, tgt_mask=tgt_mask,\n",
    "                src_key_padding_mask=src_padding_mask, tgt_key_padding_mask=tgt_padding_mask\n",
    "            )\n",
    "            loss = loss_function(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            loss = loss / accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_loader))\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(val_dataloader):\n",
    "            src, tgt = tokenize_batch(src, tgt, tokenizer)\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            src_mask = torch.zeros((src.size(1), src.size(1)), device=device)\n",
    "            tgt_mask = create_triu_mask(tgt_input.size(1)).to(device)\n",
    "            src_padding_mask = create_padding_mask(src).to(device)\n",
    "            tgt_padding_mask = create_padding_mask(tgt_input).to(device)\n",
    "            logits = model(\n",
    "                src, tgt_input,\n",
    "                src_mask=src_mask, tgt_mask=tgt_mask,\n",
    "                src_key_padding_mask=src_padding_mask, tgt_key_padding_mask=tgt_padding_mask\n",
    "            )\n",
    "            tgt_out = tgt[:, 1:]\n",
    "            loss = loss_function(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            losses += loss.item()\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOXBEOakYYMy"
   },
   "source": [
    "Now we can start training! Keep in mind this code is very demanding computationally, it has been set to 10 epochs (which can take up to 6-8 hours) but feel free to change this value depending on your resources, in this case the more epochs you can execute the better ðŸ˜€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55HSxWxs_VLV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "15784368-e9b7-45ff-a651-f822fdf444b9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:19<00:00,  4.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Train loss: 5.813, Val loss: 5.280\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:19<00:00,  4.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 11.09it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 2, Train loss: 4.576, Val loss: 4.697\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:15<00:00,  4.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 11.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 3, Train loss: 4.049, Val loss: 4.437\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:14<00:00,  4.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.86it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 4, Train loss: 3.686, Val loss: 4.251\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:18<00:00,  4.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.90it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 5, Train loss: 3.400, Val loss: 4.074\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:17<00:00,  4.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 6, Train loss: 3.160, Val loss: 3.924\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:14<00:00,  4.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.66it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 7, Train loss: 2.960, Val loss: 3.832\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:19<00:00,  4.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 8, Train loss: 2.788, Val loss: 3.681\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:18<00:00,  4.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.98it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 9, Train loss: 2.640, Val loss: 3.635\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1563/1563 [06:14<00:00,  4.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:01<00:00, 10.64it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 10, Train loss: 2.513, Val loss: 3.568\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, epochs, train_loader, validation_loader):\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_epoch(model, train_loader, tokenizer, scaler)\n",
    "        val_loss = evaluate(model, validation_loader)\n",
    "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n",
    "train(model, 1, train_loader,validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-fyWwVLZCOl"
   },
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SFHr7KgZEXg"
   },
   "source": [
    "In this assignment, we will use three different evaluation metrics to see our model's test performance: [Bert Score](https://huggingface.co/spaces/evaluate-metric/bertscore), [Meteor](https://huggingface.co/spaces/evaluate-metric/meteor) and [Rouge](https://huggingface.co/spaces/evaluate-metric/rouge). Please access their hugging face documentation to know how to implement them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAwdvSLIIJ2K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3b9e0a84-8b32-4341-86ae-912171e171c5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "rouge = load('rouge')\n",
    "meteor = load('meteor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4VJA2vfZx4o"
   },
   "source": [
    "Implement greedy decode as seen in class in the NLG slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M854C4naGHW6"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol, repetition_penalty=1.5, top_k=10, max_repetitions=5):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    repetition_counter = defaultdict(int)\n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = create_triu_mask(ys.size(1)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        logits = model.fc(out[:, -1])\n",
    "        for token_id, count in repetition_counter.items():\n",
    "            if count > 0:\n",
    "                logits[0, token_id] /= (repetition_penalty ** count)\n",
    "        topk_prob, topk_indices = torch.topk(logits, top_k, dim=-1)\n",
    "        next_word_index = torch.multinomial(torch.nn.functional.softmax(topk_prob, dim=-1), 1).item()\n",
    "        next_word = topk_indices[0, next_word_index].item()\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "        repetition_counter[next_word] += 1\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if repetition_counter[next_word] >= max_repetitions:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str, tokenizer):\n",
    "    model.eval()\n",
    "    src, _ = tokenize_batch(src_sentence, \"\", tokenizer)\n",
    "    src = src.to(device)\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.float).to(device)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len= int(num_tokens * 1.2 ), start_symbol=BOS_IDX).flatten()\n",
    "    return tokenizer.decode(tgt_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9a9f4cd3-79fa-4901-e0eb-7015c2a62867",
    "id": "66o7XXJRuVPO"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "comment vous avez comment\n"
     ]
    }
   ],
   "source": [
    "print(translate(model, \"Hello how are you today\",tokenizer))\n",
    "print(translate(model, \"Hi\",tokenizer))\n",
    "print(translate(model, \"I live in Montreal\",tokenizer))\n",
    "print(translate(model, \"There are two cats in the room\",tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def test(test_loader, model, tokenizer, device, max_length=200):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    meteor_metric = 0\n",
    "    for src, target in test_loader:\n",
    "        src_tensor, _ = tokenize_batch([src], [\"\"], tokenizer)\n",
    "        src_tensor = src_tensor.to(device)\n",
    "        translated_output = translate(model, tokenizer.decode(src_tensor[0]), tokenizer)\n",
    "        target_sentence = target[0]\n",
    "        bert_results = bertscore.compute(predictions=[translated_output], references=[target_sentence], lang='fr')\n",
    "        meteor_results = meteor.compute(predictions=[translated_output], references=[target_sentence])\n",
    "        precision += bert_results['precision'][0]\n",
    "        recall += bert_results['recall'][0]\n",
    "        f1 += bert_results['f1'][0]\n",
    "        meteor_metric += meteor_results['meteor']\n",
    "    num_samples = len(test_loader)\n",
    "    return precision / num_samples, recall / num_samples, f1 / num_samples, meteor_metric / num_samples\n",
    "\n",
    "test(test_set, model, tokenizer, device)"
   ],
   "metadata": {
    "id": "3Kqprzu9z5RH",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "02c2f2c5d79341eeba1a8ac2aa2c60ca",
      "058fe849fb0047d4b3775f1a64f9f4f0",
      "eeead8f4538e4b49b0438178e6a53df7",
      "7289b7cd0b054a189069e9dbfca286dd",
      "da7047974405424ab4de87b52f281b0c",
      "7d6ed9aba22e41a2a2bf0caef71284fd",
      "e2c57bb492794821885ec38a5615a98d",
      "3392a42034f4402383aa1fc4786968ab",
      "56dee1ed26684168b8e9c0108b818b05",
      "8b412876d03e4ad6b0070ad837ba245a",
      "6d0b87dde679459a8d3d2d8820abd57f",
      "58157b29c8704d8d95c5d401c014e518",
      "4f5874bb483346579d6e2e5cd9517bb1",
      "f70ec2d680f04eb39888f26ccf86ca5b",
      "4442d125c634403c9728a5788b4fad4a",
      "156c3aea6c194ed3bba4cda762f72cbd",
      "bfb33fd5e8114474923b9f5bafb345b1",
      "d37be210ba0942f4b565203574279295",
      "d129ae4a332349d7be37ec0d0be037af",
      "35880a07201241c4a95c1c722bc88d40",
      "8b7e3a0454c64a2facb152b5a2fee389",
      "c1ab504a720e4718a40822734e7b615f",
      "2c9158baffc040bb90954f2f015f4e30",
      "da24c058f52f4026a30dd595b40fa72b",
      "acf01872627242d8be6978b698e2ad57",
      "fecf77acb5fa488b912b0fde6c456aa0",
      "7e4a07a8c1d94dee80ffc12ec4f850da",
      "051da49a50864764bb6d221192b32642",
      "c875537150ca4835ba4658586100f871",
      "6134bc144bd64ef9be73155c8d2f64d0",
      "29a8bbbfbd854716abc7c316d993563d",
      "fbbb4228c3e24f9caabdd48c16b0b8ab",
      "ca117c7ac9cb4420be02442c2c3db432",
      "8a81cda28cba429ca81af9133251ace1",
      "d37235351713489c8956d9be4ae70037",
      "46d9c81b6d6d47d18ea3d9043e1f6422",
      "896a52a5c2944a1f886fd5e50b2a5d58",
      "2b6c9dacdac44a7ba8fc71da8ec8ba07",
      "cf40262f73b6418b8115e4d0f5b466b7",
      "1225e3d0a37f4899a18abc5785b60044",
      "b5fbc03dbe9e497087710e672dfb7bdd",
      "f1d95501cd2e4734ad00eab1a873f389",
      "0781ad7e32ae4118baf42cd591a0d0c9",
      "b55ffa5c7e5d46658e6e59754c58e465",
      "0bab079a3d8b4d2f873e1cc5054189bf",
      "905792627f394dbfb4314fba077bbc71",
      "948c76f339234a698cfb736bf0d86eb2",
      "cc3e8f9924194718affab7c27a6a611e",
      "2d3dcf7a8f354b52b09035cd4bd917ec",
      "e51a00c51df14eb49117852df55e004a",
      "c0e25fbed22f468087dae568132b59f8",
      "6d981d1957bd432b8c2d96cc357e8f62",
      "bf4dd70fc32849f4ac36702aba9f7fa7",
      "4d559483eb88416f8d8dc2f82d7ed4bd",
      "cfed253102544ca994cb62d6e5d65c7c"
     ]
    },
    "outputId": "bb8a5e20-b4eb-47b5-cae4-bbfe59ab85a2",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02c2f2c5d79341eeba1a8ac2aa2c60ca"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58157b29c8704d8d95c5d401c014e518"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c9158baffc040bb90954f2f015f4e30"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a81cda28cba429ca81af9133251ace1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bab079a3d8b4d2f873e1cc5054189bf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5954862767920406,\n",
       " 0.7134637086422232,\n",
       " 0.6467910342276394,\n",
       " 0.30765436145334296)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np_Eg1L-sgK5"
   },
   "source": [
    "## Let's experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u54CCcr74NK"
   },
   "source": [
    "1. Play with a hyperparameter of your choice to measure its effect on the translation.\n",
    "\n",
    "2. Compare the results of your model with the performance of using the T5 pretrained model. This [tutorial](https://huggingface.co/docs/transformers/en/tasks/translation) on using T5 for machine translation might come in handy.\n",
    "\n",
    "## Code of T5"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T04:00:02.176600Z",
     "start_time": "2024-12-09T03:59:58.166394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_t5_input_for_training(dataset, source_lang=\"English\", target_lang=\"French\"):\n",
    "    inputs = [f\"translate {source_lang} to {target_lang}: {src}\" for src, tgt in dataset]\n",
    "    targets = [tgt for src, tgt in dataset]\n",
    "    return inputs, targets\n",
    "\n",
    "train_inputs, train_targets = preprocess_t5_input_for_training(training_set)\n",
    "val_inputs, val_targets = preprocess_t5_input_for_training(validation_set)\n",
    "test_inputs, test_targets = preprocess_t5_input_for_training(test_set)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"t5-small\"\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def translate_with_t5(t5_model, t5_tokenizer, sentences, device, max_length=200):\n",
    "    inputs = t5_tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "    outputs = t5_model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_length=max_length)\n",
    "    return t5_tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from bert_score import score as bert_score\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "def evaluate_translation_model(model, tokenizer, test_sentences, reference_sentences, device, is_t5=False, max_length=200):\n",
    "    generated_translations, meteor_metric = [], 0\n",
    "    for src_sentence in test_sentences:\n",
    "        if is_t5:\n",
    "            inputs = tokenizer(src_sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length).to(device)\n",
    "            outputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_length=max_length)\n",
    "            translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        else:\n",
    "            translation = translate(model, src_sentence, tokenizer)\n",
    "        generated_translations.append(translation)\n",
    "    P, R, F1 = bert_score(generated_translations, reference_sentences, lang=\"en\")\n",
    "    precision = P.mean().item()\n",
    "    recall = R.mean().item()\n",
    "    f1 = F1.mean().item()\n",
    "    for ref, hyp in zip(reference_sentences, generated_translations):\n",
    "        meteor_metric += single_meteor_score(ref.split(), hyp.split())\n",
    "    return generated_translations, precision, recall, f1, meteor_metric / len(reference_sentences)\n",
    "test_src_sentences = [src for src, _ in test_set[:10]]\n",
    "test_ref_sentences = [tgt for _, tgt in test_set[:10]]\n",
    "generated_translations, precision, recall, f1, meteor_metric = evaluate_translation_model(\n",
    "    model=t5_model,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    test_sentences=test_src_sentences,\n",
    "    reference_sentences=test_ref_sentences,\n",
    "    device=device,\n",
    "    is_t5=True\n",
    ")\n",
    "print(\"Sample Translations:\")\n",
    "for i in range(5):\n",
    "    print(f\"Source: {test_src_sentences[i]}\")\n",
    "    print(f\"Generated Translation: {generated_translations[i]}\")\n",
    "    print(f\"Reference Translation: {test_ref_sentences[i]}\\n\")\n",
    "print(f\"T5 Model - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, METEOR: {meteor_metric:.4f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from bert_score import score as bert_score\n",
    "from evaluate import load as load_metric\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "rouge = load_metric('rouge')\n",
    "def evaluate_translation_model(model, tokenizer, test_sentences, reference_sentences, device, is_t5=False, max_length=200):\n",
    "    generated_translations = []\n",
    "    meteor_metric = 0\n",
    "    for src_sentence in test_sentences:\n",
    "        if is_t5:\n",
    "            inputs = tokenizer(src_sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length).to(device)\n",
    "            outputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_length=max_length)\n",
    "            translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        else:\n",
    "            translation = translate(model, src_sentence, tokenizer)\n",
    "        generated_translations.append(translation)\n",
    "    P, R, F1 = bert_score(generated_translations, reference_sentences, lang=\"en\")\n",
    "    precision = P.mean().item()\n",
    "    recall = R.mean().item()\n",
    "    f1 = F1.mean().item()\n",
    "    rouge_scores = rouge.compute(predictions=generated_translations, references=reference_sentences)\n",
    "    for ref, hyp in zip(reference_sentences, generated_translations):\n",
    "        meteor_metric += single_meteor_score(ref.split(), hyp.split())\n",
    "    return generated_translations, precision, recall, f1, meteor_metric / len(reference_sentences), rouge_scores\n",
    "test_src_sentences = [src for src, _ in test_set[:10]]\n",
    "test_ref_sentences = [tgt for _, tgt in test_set[:10]]\n",
    "generated_translations, precision, recall, f1, meteor_metric, rouge_scores = evaluate_translation_model(\n",
    "    model=t5_model,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    test_sentences=test_src_sentences,\n",
    "    reference_sentences=test_ref_sentences,\n",
    "    device=device,\n",
    "    is_t5=True\n",
    ")\n",
    "print(\"Sample Translations:\")\n",
    "for i in range(5):\n",
    "    print(f\"Source: {test_src_sentences[i]}\")\n",
    "    print(f\"Generated Translation: {generated_translations[i]}\")\n",
    "    print(f\"Reference Translation: {test_ref_sentences[i]}\\n\")\n",
    "print(f\"T5 Model - Precision (BERTScore): {precision:.4f}, Recall (BERTScore): {recall:.4f}, F1 (BERTScore): {f1:.4f}, METEOR: {meteor_metric:.4f}\")\n",
    "print(f\"ROUGE Scores: {rouge_scores}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "avg_f1_score = (rouge_scores['rouge1'] + rouge_scores['rouge2'] + rouge_scores['rougeL']) / 3\n",
    "print(f\"Average ROUGE F1 Score: {avg_f1_score:.4f}\")\n",
    "print(rouge_scores)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "avg_f1_score = (rouge_scores['rouge1'] + rouge_scores['rouge2'] + rouge_scores['rougeL'] + rouge_scores['rougeLsum']) / 4\n",
    "print(f\"Average ROUGE F1 Score (including ROUGE-Lsum): {avg_f1_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02c2f2c5d79341eeba1a8ac2aa2c60ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_058fe849fb0047d4b3775f1a64f9f4f0",
       "IPY_MODEL_eeead8f4538e4b49b0438178e6a53df7",
       "IPY_MODEL_7289b7cd0b054a189069e9dbfca286dd"
      ],
      "layout": "IPY_MODEL_da7047974405424ab4de87b52f281b0c"
     }
    },
    "058fe849fb0047d4b3775f1a64f9f4f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d6ed9aba22e41a2a2bf0caef71284fd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e2c57bb492794821885ec38a5615a98d",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "eeead8f4538e4b49b0438178e6a53df7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3392a42034f4402383aa1fc4786968ab",
      "max": 49,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56dee1ed26684168b8e9c0108b818b05",
      "value": 49
     }
    },
    "7289b7cd0b054a189069e9dbfca286dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b412876d03e4ad6b0070ad837ba245a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6d0b87dde679459a8d3d2d8820abd57f",
      "value": "â€‡49.0/49.0â€‡[00:00&lt;00:00,â€‡4.23kB/s]"
     }
    },
    "da7047974405424ab4de87b52f281b0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d6ed9aba22e41a2a2bf0caef71284fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2c57bb492794821885ec38a5615a98d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3392a42034f4402383aa1fc4786968ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56dee1ed26684168b8e9c0108b818b05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8b412876d03e4ad6b0070ad837ba245a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d0b87dde679459a8d3d2d8820abd57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58157b29c8704d8d95c5d401c014e518": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f5874bb483346579d6e2e5cd9517bb1",
       "IPY_MODEL_f70ec2d680f04eb39888f26ccf86ca5b",
       "IPY_MODEL_4442d125c634403c9728a5788b4fad4a"
      ],
      "layout": "IPY_MODEL_156c3aea6c194ed3bba4cda762f72cbd"
     }
    },
    "4f5874bb483346579d6e2e5cd9517bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfb33fd5e8114474923b9f5bafb345b1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d37be210ba0942f4b565203574279295",
      "value": "config.json:â€‡100%"
     }
    },
    "f70ec2d680f04eb39888f26ccf86ca5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d129ae4a332349d7be37ec0d0be037af",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35880a07201241c4a95c1c722bc88d40",
      "value": 625
     }
    },
    "4442d125c634403c9728a5788b4fad4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b7e3a0454c64a2facb152b5a2fee389",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c1ab504a720e4718a40822734e7b615f",
      "value": "â€‡625/625â€‡[00:00&lt;00:00,â€‡57.4kB/s]"
     }
    },
    "156c3aea6c194ed3bba4cda762f72cbd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bfb33fd5e8114474923b9f5bafb345b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d37be210ba0942f4b565203574279295": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d129ae4a332349d7be37ec0d0be037af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35880a07201241c4a95c1c722bc88d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8b7e3a0454c64a2facb152b5a2fee389": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1ab504a720e4718a40822734e7b615f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c9158baffc040bb90954f2f015f4e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da24c058f52f4026a30dd595b40fa72b",
       "IPY_MODEL_acf01872627242d8be6978b698e2ad57",
       "IPY_MODEL_fecf77acb5fa488b912b0fde6c456aa0"
      ],
      "layout": "IPY_MODEL_7e4a07a8c1d94dee80ffc12ec4f850da"
     }
    },
    "da24c058f52f4026a30dd595b40fa72b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_051da49a50864764bb6d221192b32642",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c875537150ca4835ba4658586100f871",
      "value": "vocab.txt:â€‡100%"
     }
    },
    "acf01872627242d8be6978b698e2ad57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6134bc144bd64ef9be73155c8d2f64d0",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_29a8bbbfbd854716abc7c316d993563d",
      "value": 995526
     }
    },
    "fecf77acb5fa488b912b0fde6c456aa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbbb4228c3e24f9caabdd48c16b0b8ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ca117c7ac9cb4420be02442c2c3db432",
      "value": "â€‡996k/996kâ€‡[00:00&lt;00:00,â€‡7.73MB/s]"
     }
    },
    "7e4a07a8c1d94dee80ffc12ec4f850da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "051da49a50864764bb6d221192b32642": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c875537150ca4835ba4658586100f871": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6134bc144bd64ef9be73155c8d2f64d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29a8bbbfbd854716abc7c316d993563d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbbb4228c3e24f9caabdd48c16b0b8ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca117c7ac9cb4420be02442c2c3db432": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a81cda28cba429ca81af9133251ace1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d37235351713489c8956d9be4ae70037",
       "IPY_MODEL_46d9c81b6d6d47d18ea3d9043e1f6422",
       "IPY_MODEL_896a52a5c2944a1f886fd5e50b2a5d58"
      ],
      "layout": "IPY_MODEL_2b6c9dacdac44a7ba8fc71da8ec8ba07"
     }
    },
    "d37235351713489c8956d9be4ae70037": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf40262f73b6418b8115e4d0f5b466b7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1225e3d0a37f4899a18abc5785b60044",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "46d9c81b6d6d47d18ea3d9043e1f6422": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5fbc03dbe9e497087710e672dfb7bdd",
      "max": 1961828,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1d95501cd2e4734ad00eab1a873f389",
      "value": 1961828
     }
    },
    "896a52a5c2944a1f886fd5e50b2a5d58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0781ad7e32ae4118baf42cd591a0d0c9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b55ffa5c7e5d46658e6e59754c58e465",
      "value": "â€‡1.96M/1.96Mâ€‡[00:00&lt;00:00,â€‡24.3MB/s]"
     }
    },
    "2b6c9dacdac44a7ba8fc71da8ec8ba07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf40262f73b6418b8115e4d0f5b466b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1225e3d0a37f4899a18abc5785b60044": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5fbc03dbe9e497087710e672dfb7bdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1d95501cd2e4734ad00eab1a873f389": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0781ad7e32ae4118baf42cd591a0d0c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b55ffa5c7e5d46658e6e59754c58e465": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bab079a3d8b4d2f873e1cc5054189bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_905792627f394dbfb4314fba077bbc71",
       "IPY_MODEL_948c76f339234a698cfb736bf0d86eb2",
       "IPY_MODEL_cc3e8f9924194718affab7c27a6a611e"
      ],
      "layout": "IPY_MODEL_2d3dcf7a8f354b52b09035cd4bd917ec"
     }
    },
    "905792627f394dbfb4314fba077bbc71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e51a00c51df14eb49117852df55e004a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c0e25fbed22f468087dae568132b59f8",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "948c76f339234a698cfb736bf0d86eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d981d1957bd432b8c2d96cc357e8f62",
      "max": 714290682,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf4dd70fc32849f4ac36702aba9f7fa7",
      "value": 714290682
     }
    },
    "cc3e8f9924194718affab7c27a6a611e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d559483eb88416f8d8dc2f82d7ed4bd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cfed253102544ca994cb62d6e5d65c7c",
      "value": "â€‡714M/714Mâ€‡[00:03&lt;00:00,â€‡231MB/s]"
     }
    },
    "2d3dcf7a8f354b52b09035cd4bd917ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e51a00c51df14eb49117852df55e004a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0e25fbed22f468087dae568132b59f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d981d1957bd432b8c2d96cc357e8f62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf4dd70fc32849f4ac36702aba9f7fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d559483eb88416f8d8dc2f82d7ed4bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfed253102544ca994cb62d6e5d65c7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
